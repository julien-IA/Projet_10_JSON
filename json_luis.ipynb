{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Elaboration du fichier json et entrainement de LUIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Hello, I am looking to book a vacation from Gotham City to Mos Eisley for $2100.', 'labels': {'acts': [{'args': [{'val': 'book', 'key': 'intent'}], 'name': 'inform'}, {'args': [{'val': 'Mos Eisley', 'key': 'dst_city'}, {'val': 'Gotham City', 'key': 'or_city'}, {'val': '2100', 'key': 'budget'}], 'name': 'inform'}, {'args': [], 'name': 'greeting'}], 'acts_without_refs': [{'args': [{'val': 'book', 'key': 'intent'}], 'name': 'inform'}, {'args': [{'val': 'Mos Eisley', 'key': 'dst_city'}, {'val': 'Gotham City', 'key': 'or_city'}, {'val': '2100', 'key': 'budget'}], 'name': 'inform'}, {'args': [], 'name': 'greeting'}], 'active_frame': 1, 'frames': [{'info': {'intent': [{'val': 'book', 'negated': False}], 'or_city': [{'val': 'Gotham City', 'negated': False}], 'dst_city': [{'val': 'Mos Eisley', 'negated': False}], 'budget': [{'val': '2100.0', 'negated': False}]}, 'frame_id': 1, 'requests': [], 'frame_parent_id': None, 'binary_questions': [], 'compare_requests': []}]}, 'author': 'user', 'timestamp': 1471271993727.0}\n"
     ]
    }
   ],
   "source": [
    "# Chagement du  fichier Frame\n",
    "\n",
    "with open('frames\\\\frames.json') as fichier_frames:\n",
    "    data = json.load(fichier_frames)\n",
    "print(data[1]['turns'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation du fichier frames en dataset avec les données utiles à LUIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'dst_city'}\n",
      "{'key': 'dst_city'}\n",
      "{'key': 'dst_city'}\n"
     ]
    }
   ],
   "source": [
    "class create_luis_df:\n",
    "    def __init__(self, frames_file):\n",
    "        self.data = None\n",
    "        self.df_data = None\n",
    "        self.frames_file = frames_file\n",
    "    \n",
    "    def init_df_data(self):\n",
    "        self.df_data = pd.DataFrame(columns=['text',\n",
    "                                                    'from',\n",
    "                                                    'from_start_pos',\n",
    "                                                    'from_end_pos',\n",
    "                                                    'to',\n",
    "                                                    'to_start_pos',\n",
    "                                                    'to_end_pos',\n",
    "                                                    'str_date',\n",
    "                                                    'str_date_start_pos',\n",
    "                                                    'str_date_end_pos',\n",
    "                                                    'end_date',\n",
    "                                                    'end_date_start_pos',\n",
    "                                                    'end_date_end_pos',\n",
    "                                                    'budget',\n",
    "                                                    'budget_start_pos',\n",
    "                                                    'budget_end_pos',\n",
    "                                                    'stratification'\n",
    "                                            ])\n",
    "\n",
    "    def get_data(self):\n",
    "        with open(self.frames_file) as fichier_frames:\n",
    "            self.data = json.load(fichier_frames)\n",
    "    \n",
    "    def get_pos(self, first_turn, keyword):\n",
    "        start_pos, expression = self.get_start_pos(first_turn, keyword)\n",
    "        end_pos = self.get_end_pos(start_pos, expression)\n",
    "        return(start_pos, end_pos, expression)\n",
    "\n",
    "    def get_start_pos(self, first_turn, keyword) -> int:\n",
    "        if (type(first_turn['labels']['acts'])==list and len(first_turn['labels']['acts'])>1):\n",
    "            for act in first_turn['labels']['acts']:\n",
    "                if('args' in act):\n",
    "                    dicts=act['args']\n",
    "                    for dict in dicts:                  \n",
    "                        if (dict['key']==keyword):\n",
    "                            if('val' in dict):\n",
    "                                expression = dict['val']\n",
    "                                start_pos = first_turn['text'].find(expression)\n",
    "                                if(start_pos>0):                    \n",
    "                                    return (start_pos, expression)\n",
    "                                else:\n",
    "                                    return(None, None)\n",
    "                            else:\n",
    "                                print(dict)\n",
    "        return(None, None)\n",
    "\n",
    "    def get_end_pos(self, start_pos, expression) -> int:\n",
    "        if(not start_pos == None):\n",
    "            return (start_pos + len(expression)-1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def charge_df_data(self):       \n",
    "        for one_data in self.data:\n",
    "            first_turn = one_data['turns'][0]\n",
    "            text = one_data['turns'][0]['text']\n",
    "            from_start_pos, from_end_pos, or_city = self.get_pos(first_turn, 'or_city')\n",
    "            to_start_pos, to_end_pos, dst_city = self.get_pos(first_turn, 'dst_city')\n",
    "            depart_date_start_pos, depart_date_end_pos, str_date = self.get_pos(first_turn, 'str_date')\n",
    "            return_date_start_pos, return_date_end_pos, end_date = self.get_pos(first_turn, 'end_date')\n",
    "            max_price_start_pos, max_price_end_pos, budget = self.get_pos(first_turn, 'budget')\n",
    "            stratification=(\"0\" if(or_city==None) else \"1\")+(\"0\" if(dst_city==None) else \"1\")+(\"0\" if(str_date==None) else \"1\")+(\"0\" if(end_date==None) else \"1\")+(\"0\" if(budget==None) else \"1\")\n",
    "\n",
    "            df_new_row = pd.DataFrame(  data=np.array([[\n",
    "                                                        text,\n",
    "                                                        or_city,\n",
    "                                                        from_start_pos,\n",
    "                                                        from_end_pos,\n",
    "                                                        dst_city,\n",
    "                                                        to_start_pos,\n",
    "                                                        to_end_pos,\n",
    "                                                        str_date,\n",
    "                                                        depart_date_start_pos,\n",
    "                                                        depart_date_end_pos,\n",
    "                                                        end_date,                                                        \n",
    "                                                        return_date_start_pos,\n",
    "                                                        return_date_end_pos,\n",
    "                                                        budget,\n",
    "                                                        max_price_start_pos,\n",
    "                                                        max_price_end_pos,\n",
    "                                                        stratification\n",
    "                                                    ]]),\n",
    "                                        columns=[\n",
    "                                                    'text',\n",
    "                                                    'from',\n",
    "                                                    'from_start_pos',\n",
    "                                                    'from_end_pos',\n",
    "                                                    'to',\n",
    "                                                    'to_start_pos',\n",
    "                                                    'to_end_pos',\n",
    "                                                    'str_date',\n",
    "                                                    'str_date_start_pos',\n",
    "                                                    'str_date_end_pos',\n",
    "                                                    'end_date',\n",
    "                                                    'end_date_start_pos',\n",
    "                                                    'end_date_end_pos',\n",
    "                                                    'budget',\n",
    "                                                    'budget_start_pos',\n",
    "                                                    'budget_end_pos',\n",
    "                                                    'stratification'\n",
    "                                                ])\n",
    "            self.df_data = pd.concat([self.df_data,df_new_row], ignore_index=True)\n",
    "    \n",
    "    def pipeline(self):\n",
    "        self.init_df_data()\n",
    "        self.get_data()\n",
    "        self.charge_df_data()\n",
    "\n",
    "\n",
    "monEssai = create_luis_df(\"frames\\\\frames.json\")\n",
    "monEssai.pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>from</th>\n",
       "      <th>from_start_pos</th>\n",
       "      <th>from_end_pos</th>\n",
       "      <th>to</th>\n",
       "      <th>to_start_pos</th>\n",
       "      <th>to_end_pos</th>\n",
       "      <th>str_date</th>\n",
       "      <th>str_date_start_pos</th>\n",
       "      <th>str_date_end_pos</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_date_start_pos</th>\n",
       "      <th>end_date_end_pos</th>\n",
       "      <th>budget</th>\n",
       "      <th>budget_start_pos</th>\n",
       "      <th>budget_end_pos</th>\n",
       "      <th>stratification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1369</td>\n",
       "      <td>653</td>\n",
       "      <td>653</td>\n",
       "      <td>653</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1329</td>\n",
       "      <td>228</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>228</td>\n",
       "      <td>180</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>140</td>\n",
       "      <td>145</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>119</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>hi</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>Punta Cana</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>August 27th</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>16</td>\n",
       "      <td>62</td>\n",
       "      <td>71</td>\n",
       "      <td>3200</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text     from  from_start_pos  from_end_pos          to  to_start_pos  \\\n",
       "count   1369      653             653           653         752           752   \n",
       "unique  1329      228             174           175         228           180   \n",
       "top       hi  Beijing              32            38  Punta Cana            16   \n",
       "freq      10       13              18            18          17            33   \n",
       "\n",
       "        to_end_pos     str_date  str_date_start_pos  str_date_end_pos  \\\n",
       "count          752          305                 305               305   \n",
       "unique         177          177                 140               145   \n",
       "top             25  August 27th                  48                58   \n",
       "freq            26           12                  10                 8   \n",
       "\n",
       "       end_date  end_date_start_pos  end_date_end_pos budget  \\\n",
       "count       173                 173               173    184   \n",
       "unique      128                 114               119    106   \n",
       "top          16                  62                71   3200   \n",
       "freq          5                   6                 5      7   \n",
       "\n",
       "        budget_start_pos  budget_end_pos stratification  \n",
       "count                184             184           1369  \n",
       "unique               128             130             25  \n",
       "top                    7              42          00000  \n",
       "freq                   6               4            383  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monEssai.df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>from</th>\n",
       "      <th>from_start_pos</th>\n",
       "      <th>from_end_pos</th>\n",
       "      <th>to</th>\n",
       "      <th>to_start_pos</th>\n",
       "      <th>to_end_pos</th>\n",
       "      <th>str_date</th>\n",
       "      <th>str_date_start_pos</th>\n",
       "      <th>str_date_end_pos</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_date_start_pos</th>\n",
       "      <th>end_date_end_pos</th>\n",
       "      <th>budget</th>\n",
       "      <th>budget_start_pos</th>\n",
       "      <th>budget_end_pos</th>\n",
       "      <th>stratification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to book a trip to Atlantis from Capri...</td>\n",
       "      <td>Caprica</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>Atlantis</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>Saturday, August 13, 2016</td>\n",
       "      <td>52</td>\n",
       "      <td>76</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1700</td>\n",
       "      <td>117</td>\n",
       "      <td>120</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello, I am looking to book a vacation from Go...</td>\n",
       "      <td>Gotham City</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>Mos Eisley</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2100</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>11001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello there i am looking to go on a vacation w...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Gotham City</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi I'd like to go to Caprica from Busan, betwe...</td>\n",
       "      <td>Busan</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>Caprica</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>Sunday August 21, 2016</td>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>Wednesday August 31, 2016</td>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello, I am looking to book a trip for 2 adult...</td>\n",
       "      <td>Kochi</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>Denver</td>\n",
       "      <td>116</td>\n",
       "      <td>121</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>$21,300</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>11001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         from  \\\n",
       "0  I'd like to book a trip to Atlantis from Capri...      Caprica   \n",
       "1  Hello, I am looking to book a vacation from Go...  Gotham City   \n",
       "2  Hello there i am looking to go on a vacation w...         None   \n",
       "3  Hi I'd like to go to Caprica from Busan, betwe...        Busan   \n",
       "4  Hello, I am looking to book a trip for 2 adult...        Kochi   \n",
       "\n",
       "  from_start_pos from_end_pos           to to_start_pos to_end_pos  \\\n",
       "0             41           47     Atlantis           27         34   \n",
       "1             44           54   Mos Eisley           59         68   \n",
       "2           None         None  Gotham City           63         73   \n",
       "3             34           38      Caprica           21         27   \n",
       "4            106          110       Denver          116        121   \n",
       "\n",
       "                    str_date str_date_start_pos str_date_end_pos  \\\n",
       "0  Saturday, August 13, 2016                 52               76   \n",
       "1                       None               None             None   \n",
       "2                       None               None             None   \n",
       "3     Sunday August 21, 2016                 49               70   \n",
       "4                       None               None             None   \n",
       "\n",
       "                    end_date end_date_start_pos end_date_end_pos   budget  \\\n",
       "0                       None               None             None     1700   \n",
       "1                       None               None             None     2100   \n",
       "2                       None               None             None     None   \n",
       "3  Wednesday August 31, 2016                 76              100     None   \n",
       "4                       None               None             None  $21,300   \n",
       "\n",
       "  budget_start_pos budget_end_pos stratification  \n",
       "0              117            120          11101  \n",
       "1               75             78          11001  \n",
       "2             None           None          01000  \n",
       "3             None           None          11110  \n",
       "4               67             73          11001  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monEssai.df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00000    383\n",
       "11000    248\n",
       "01000    213\n",
       "10000     97\n",
       "11001     70\n",
       "11100     59\n",
       "11110     56\n",
       "11111     23\n",
       "10100     23\n",
       "10110     23\n",
       "01100     21\n",
       "01110     21\n",
       "00110     21\n",
       "10001     19\n",
       "00001     17\n",
       "11101     15\n",
       "10111     15\n",
       "00100     14\n",
       "01001     11\n",
       "01101      5\n",
       "01111      5\n",
       "11010      5\n",
       "00111      3\n",
       "00010      1\n",
       "00101      1\n",
       "Name: stratification, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monEssai.df_data['stratification'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation du dataset en json exploitable par LUIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_luis_data:\n",
    "    def __init__(\n",
    "                    self,\n",
    "                    df_frames,\n",
    "                    file_name_json          =\"D:\\\\projets_ocr\\\\01_projets_python\\\\Projet_10_JSON\\\\data.json\",\n",
    "                    luis_schema_version     =\"3.2.0\",\n",
    "                    versionId               =\"0.1\",\n",
    "                    name                    =\"projet_10_fly_booking\",\n",
    "                    desc                    =\"A LUIS model for booking a fly.\",\n",
    "                    culture                 =\"en-us\",\n",
    "                    tokenizerVersion        =\"1.0.0\",\n",
    "                    intents_list            =['BookFlight'],\n",
    "                    entities_list           =['from', 'to', 'str_date', 'end_date', 'budget'],\n",
    "                    composites_list         =[],\n",
    "                    patternAnyEntities_list =[],\n",
    "                    regex_entities_list     =[],\n",
    "                    prebuiltEntities_list   =[],\n",
    "                    model_features_list     =[],\n",
    "                    regex_features_list     =[],\n",
    "                    patterns_list           =[],\n",
    "                    utterances_list         =[],\n",
    "                ):\n",
    "        self.df_data                    = df_frames\n",
    "        self.file_name_json             = file_name_json\n",
    "        self.luis_schema_version        = luis_schema_version\n",
    "        self.versionId                  = versionId\n",
    "        self.name                       = name\n",
    "        self.desc                       = desc\n",
    "        self.culture                    = culture\n",
    "        self.tokenizerVersion           = tokenizerVersion\n",
    "        self.intents_list               = intents_list\n",
    "        self.entities_list              = entities_list\n",
    "        self.composites_list            = composites_list\n",
    "        self.patternAnyEntities_list    = patternAnyEntities_list\n",
    "        self.regex_entities_list        = regex_entities_list\n",
    "        self.prebuiltEntities_list      = prebuiltEntities_list\n",
    "        self.regex_features_list        = regex_features_list\n",
    "        self.patterns_list              = patterns_list\n",
    "        self.utterances_list            = utterances_list\n",
    "        \n",
    "\n",
    "    def luis_structure_python(self)->dict:\n",
    "        struct_pyth = {}\n",
    "        struct_pyth[\"luis_schema_version\"]      = self.luis_schema_version\n",
    "        struct_pyth[\"versionId\"]                = self.versionId\n",
    "        struct_pyth[\"name\"]                     = self.name\n",
    "        struct_pyth[\"desc\"]                     = self.desc\n",
    "        struct_pyth[\"culture\"]                  = self.culture\n",
    "        struct_pyth[\"tokenizerVersion\"]         = self.tokenizerVersion\n",
    "        struct_pyth[\"intents\"]                  = self.get_intents()\n",
    "        struct_pyth[\"entities\"]                 = self.get_entities()\n",
    "        struct_pyth[\"composites\"]               = self.get_composites()\n",
    "        struct_pyth[\"closedLists\"]              = self.get_closedLists()\n",
    "        struct_pyth[\"patternAnyEntities\"]       = self.get_patternAnyEntities()\n",
    "        struct_pyth[\"regex_entities\"]           = self.get_regex_entities()\n",
    "        struct_pyth[\"prebuiltEntities\"]         = self.get_prebuiltEntities()\n",
    "        struct_pyth[\"model_features\"]           = self.get_model_features()\n",
    "        struct_pyth[\"regex_features\"]           = self.get_regex_features()\n",
    "        struct_pyth[\"patterns\"]                 = self.get_patterns()\n",
    "        struct_pyth[\"utterances\"]               = self.get_utterances()\n",
    "        struct_pyth[\"settings\"]                 = self.get_settings()\n",
    "        return  struct_pyth\n",
    "\n",
    "    def get_intents(self)->list:\n",
    "        result = []        \n",
    "        for intent in self.intents_list:\n",
    "            w_dict = {}\n",
    "            w_dict['name'] = intent\n",
    "            result.append(w_dict)\n",
    "        return result\n",
    "\n",
    "    def get_entities(self)->list:\n",
    "        result = []\n",
    "        for entite in self.entities_list:\n",
    "            w_dict = {}\n",
    "            w_dict['name'] = entite\n",
    "            result.append(w_dict)\n",
    "        return result\n",
    "\n",
    "    def get_composites(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "    \n",
    "    def get_closedLists(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "\n",
    "    def get_patternAnyEntities(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "\n",
    "    def get_regex_entities(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "\n",
    "    def get_prebuiltEntities(self)->list:\n",
    "        result = [{\n",
    "                    \"name\": \"datetimeV2\",\n",
    "                    \"roles\": []\n",
    "                }]\n",
    "        return result\n",
    "\n",
    "    def get_model_features(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "\n",
    "    def get_regex_features(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "\n",
    "    def get_patterns(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "\n",
    "    def get_utterances(self)->list:\n",
    "        result = []\n",
    "        for i in range(len(self.df_data)):\n",
    "            w_dict = {}\n",
    "            w_dict['text'] = self.df_data.loc[i,\"text\"]\n",
    "            w_dict['intentName'] = \"BookFlight\"\n",
    "            w_dict['entityLabels'] = self.get_utterances_entities(i)\n",
    "            # il faut coder la fonction get_utterances_entities qui permet de récupérer\n",
    "            # les entities pour une phrase\n",
    "            result.append(w_dict)\n",
    "        return result\n",
    "\n",
    "    def get_utterances_entities(self, line)->list:\n",
    "        START_POS=\"_start_pos\"\n",
    "        END_POS=\"_end_pos\"\n",
    "        result = []\n",
    "        for entity in self.entities_list:\n",
    "            # print(self.entities_list)\n",
    "            dict={}\n",
    "            # print(entity+START_POS)\n",
    "            # print(self.df_data.loc[line,entity+START_POS])\n",
    "            # print(entity+END_POS)\n",
    "            # print(self.df_data.loc[line,entity+END_POS])\n",
    "\n",
    "            if self.df_data.loc[line,entity+START_POS] != None and self.df_data.loc[line,entity+END_POS] != None:\n",
    "                dict['entityName']=entity\n",
    "                dict['startCharIndex']=self.df_data.loc[line,entity+START_POS]\n",
    "                dict['endCharIndex']=self.df_data.loc[line,entity+END_POS]\n",
    "                result.append(dict)\n",
    "        return result\n",
    "\n",
    "    def get_settings(self)->list:\n",
    "        result = []\n",
    "        return result\n",
    "\n",
    "    def save_jsons(self, struct_pyth, file_name):\n",
    "        with open(file_name, 'w') as fp:\n",
    "            json.dump(struct_pyth, fp, indent=4)\n",
    "\n",
    "    def json_pipeline(self):\n",
    "        struct_pyth = self.luis_structure_python()\n",
    "        self.save_jsons(struct_pyth, self.file_name_json)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement, test et déploiement de LUIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.language.luis.authoring import LUISAuthoringClient\n",
    "from azure.cognitiveservices.language.luis.authoring.models import ApplicationCreateObject, PrebuiltEntity, PrebuiltEntityExtractor\n",
    "from azure.cognitiveservices.language.luis.runtime import LUISRuntimeClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from functools import reduce\n",
    "\n",
    "import json, time, uuid,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DefaultConfig\n",
    "CONF= DefaultConfig()\n",
    "auth_endpoint: str = CONF.LUIS_AUTHORING_END_POINT\n",
    "auth_key: str = CONF.LUIS_AUTHORING_KEY\n",
    "pred_endpoint: str = CONF.LUIS_PREDICTION_END_POINT\n",
    "pred_key: str = CONF.LUIS_PREDICTION_KEY\n",
    "luis_app_id : str = CONF.LUIS_APP_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prépare les données d'entrainement et les données de test\n",
    "# X_train, X_test = train_test_split(monEssai.df_data, test_size=0.2, stratify=monEssai.df_data['stratification'])\n",
    "df_complet = monEssai.df_data.drop(columns=[\"stratification\"])\n",
    "df_train, df_test = train_test_split(df_complet, test_size=0.2, random_state=20)\n",
    "\n",
    "df_train=df_train.reset_index(drop=True)\n",
    "df_test=df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1095, step=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre total de lignes :  (1369, 16)\n",
      "nombre de lignes d'entrainement :  1095\n",
      "nombre de lignes de test :  274\n"
     ]
    }
   ],
   "source": [
    "print(\"nombre total de lignes : \", df_complet.shape)\n",
    "print(\"nombre de lignes d'entrainement : \",df_train.shape[0])\n",
    "print(\"nombre de lignes de test : \",df_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_luis_app():\n",
    "    def __init__(self,authoring_endpoint,authoring_key,appName,versionId,culture,app_id=None,luis_app_json=None) -> None:\n",
    "        self.endpoint           =authoring_endpoint\n",
    "        self.credentials        =CognitiveServicesCredentials(authoring_key)\n",
    "        self.appName            =appName\n",
    "        self.versionId          =versionId\n",
    "        self.client             =LUISAuthoringClient(self.endpoint, self.credentials)\n",
    "        self.luis_app_json      =luis_app_json\n",
    "        self.app_id             =app_id\n",
    "        self.culture            =culture\n",
    "        if(self.app_id==None) : self.create_app()\n",
    "    \n",
    "    def create_app(self):\n",
    "        # define app basics\n",
    "        appDefinition = ApplicationCreateObject(name=self.appName, initial_version_id=self.versionId, culture=self.culture)\n",
    "        # create app\n",
    "        self.app_id = self.client.apps.add(appDefinition)\n",
    "\n",
    "    def add_intents(self, intents):\n",
    "        for intent in intents:\n",
    "            print(intent['name'])\n",
    "            self.client.model.add_intent(self.app_id, self.versionId, intent['name'])\n",
    "    \n",
    "    def add_entities(self, entities):\n",
    "        for entitie in entities:\n",
    "            print(entitie['name'])\n",
    "            modelId=self.client.model.add_entity(self.app_id, self.versionId, name=entitie[\"name\"])\n",
    "            print(\"modelId\",modelId)\n",
    "            model_object=self.client.model.get_entity(self.app_id, self.versionId, modelId)\n",
    "            print(\"model_object\",model_object)\n",
    "    \n",
    "    def add_utterances(self, utterances):\n",
    "        for utterance in utterances:\n",
    "            self.client.examples.add(self.app_id, self.versionId, utterance)\n",
    "    \n",
    "    def train_luis(self):\n",
    "        self.client.train.train_version(self.app_id, self.versionId)\n",
    "        waiting = True\n",
    "        while waiting:\n",
    "            info = self.client.train.get_status(self.app_id, self.versionId)\n",
    "            # get_status returns a list of training statuses, one for each model.\n",
    "            # Loop through them and make sure all are done.\n",
    "            waiting = any(map(lambda x: 'Queued' == x.details.status or 'InProgress' == x.details.status, info))\n",
    "            if waiting:\n",
    "                print (\"Waiting 10 seconds for training to complete...\")\n",
    "                time.sleep(10)\n",
    "            else: \n",
    "                print (\"trained\")\n",
    "                waiting = False\n",
    "    \n",
    "    def publish_luis(self):\n",
    "        # Mark the app as public so we can query it using any prediction endpoint.\n",
    "        # Note: For production scenarios, you should instead assign the app to your own LUIS prediction endpoint. See:\n",
    "        # https://docs.microsoft.com/en-gb/azure/cognitive-services/luis/luis-how-to-azure-subscription#assign-a-resource-to-an-app\n",
    "        self.client.apps.update_settings(self.app_id, is_public=True)\n",
    "        responseEndpointInfo = self.client.apps.publish(self.app_id, self.versionId, is_staging=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_luis_data = create_luis_data(df_train)\n",
    "luis_dict = my_luis_data.luis_structure_python()\n",
    "my_app_luis=create_luis_app(\n",
    "                            auth_endpoint,\n",
    "                            auth_key,\n",
    "                            \"FlightBooking\",\n",
    "                            \"0.1\",\n",
    "                            \"en-us\",\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BookFlight\n"
     ]
    }
   ],
   "source": [
    "my_app_luis.add_intents(luis_dict[\"intents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "modelId 36791a25-b7a4-433f-9c55-167218cc0f3f\n",
      "model_object {'additional_properties': {}, 'id': '36791a25-b7a4-433f-9c55-167218cc0f3f', 'name': 'from', 'type_id': 1, 'readable_type': 'Entity Extractor', 'roles': [], 'custom_prebuilt_domain_name': None, 'custom_prebuilt_model_name': None, 'children': []}\n",
      "to\n",
      "modelId e791a37a-35fe-40d6-928c-77c97da259ab\n",
      "model_object {'additional_properties': {}, 'id': 'e791a37a-35fe-40d6-928c-77c97da259ab', 'name': 'to', 'type_id': 1, 'readable_type': 'Entity Extractor', 'roles': [], 'custom_prebuilt_domain_name': None, 'custom_prebuilt_model_name': None, 'children': []}\n",
      "str_date\n",
      "modelId 321f733d-0e11-49df-b85a-5e2c4bd3a0e6\n",
      "model_object {'additional_properties': {}, 'id': '321f733d-0e11-49df-b85a-5e2c4bd3a0e6', 'name': 'str_date', 'type_id': 1, 'readable_type': 'Entity Extractor', 'roles': [], 'custom_prebuilt_domain_name': None, 'custom_prebuilt_model_name': None, 'children': []}\n",
      "end_date\n",
      "modelId 52e082d0-77e5-4aca-b9fa-6df663492a5b\n",
      "model_object {'additional_properties': {}, 'id': '52e082d0-77e5-4aca-b9fa-6df663492a5b', 'name': 'end_date', 'type_id': 1, 'readable_type': 'Entity Extractor', 'roles': [], 'custom_prebuilt_domain_name': None, 'custom_prebuilt_model_name': None, 'children': []}\n",
      "budget\n",
      "modelId c68cf44a-3f3d-4767-bc1b-9d602f990e9f\n",
      "model_object {'additional_properties': {}, 'id': 'c68cf44a-3f3d-4767-bc1b-9d602f990e9f', 'name': 'budget', 'type_id': 1, 'readable_type': 'Entity Extractor', 'roles': [], 'custom_prebuilt_domain_name': None, 'custom_prebuilt_model_name': None, 'children': []}\n"
     ]
    }
   ],
   "source": [
    "my_app_luis.add_entities(luis_dict[\"entities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_app_luis.add_utterances(luis_dict[\"utterances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.language.luis.authoring.models._models_py3.PrebuiltEntityExtractor at 0x26ddd4d2c70>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_app_luis.client.model.add_prebuilt(app_id=my_app_luis.app_id,version_id='0.1', prebuilt_extractor_names=[\"datetimeV2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 10 seconds for training to complete...\n",
      "Waiting 10 seconds for training to complete...\n",
      "trained\n"
     ]
    }
   ],
   "source": [
    "my_app_luis.train_luis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_app_luis.publish_luis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://p10luis2023-authoring.cognitiveservices.azure.com/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_app_luis.versionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_luis_test= create_luis_data(df_test)\n",
    "struct_pyth_test = my_luis_data.luis_structure_python()\n",
    "utterance = struct_pyth_test[\"utterances\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "from\n",
      "from_start_pos\n",
      "from_end_pos\n",
      "to\n",
      "to_start_pos\n",
      "to_end_pos\n"
     ]
    }
   ],
   "source": [
    "for col in df_test.columns:\n",
    "    if(df_test.loc[1,col]!=None):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pas BookFlight\n",
      "psssstttttt\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.language.luis.authoring import LUISAuthoringClient\n",
    "from azure.cognitiveservices.language.luis.runtime import LUISRuntimeClient\n",
    "from azure.cognitiveservices.language.luis.runtime.models import PredictionRequest\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# On récupère les information de connexion\n",
    "endpoint = pred_endpoint\n",
    "authoring_key = pred_key\n",
    "runtime_key = pred_key\n",
    "app_id = my_app_luis.app_id\n",
    "true_entities={}\n",
    "wrong_entities={}\n",
    "\n",
    "# Création des instances de LUISAuthoringClient et LUISRuntimeClient\n",
    "authoring_client = LUISAuthoringClient(endpoint, CognitiveServicesCredentials(authoring_key))\n",
    "runtime_client = LUISRuntimeClient(endpoint, CognitiveServicesCredentials(runtime_key))\n",
    "\n",
    "# Pour chaque phrase du dataset de test\n",
    "for line in range(len(df_test)):\n",
    "    sorted_list_entitie=[]\n",
    "    best_result_entitie=\"\"\n",
    "    instance={}\n",
    "    # On définit la phrase à envoyer à LUIS\n",
    "    input_text = df_test.loc[line,\"text\"]\n",
    "\n",
    "    # On Crée une requête de prédiction pour LUIS\n",
    "    prediction_request = PredictionRequest(query=input_text)\n",
    "\n",
    "    # On envoie la requête de prédiction à LUIS\n",
    "    prediction_response = runtime_client.prediction.get_slot_prediction(app_id=app_id, slot_name=\"production\", prediction_request=prediction_request, verbose=True)\n",
    "\n",
    "    # On obtient la prédiction de l'intent\n",
    "    predicted_entities = prediction_response.prediction.entities\n",
    "    predicted_intent = prediction_response.prediction.intents\n",
    "    # On vérifie si la prédiction de l'intent correspond à ce qui est prévu\n",
    "    if \"BookFlight\" in predicted_intent:\n",
    "        for key, value in predicted_entities.items():\n",
    "            if(key not in ['$instance', 'datetimeV2']):\n",
    "                if predicted_entities.get(key, [{\"$instance\": {}}])[0]:\n",
    "                    instance=predicted_entities.get(\"$instance\", {}).get(key, [])\n",
    "                    sorted_list_entitie = sorted(instance, key=lambda x: x['score'], reverse=True)\n",
    "                    best_result_entitie = instance[0][\"text\"]\n",
    "\n",
    "                    if (df_test.loc[line,key]==best_result_entitie):\n",
    "                        # Bonne prédiction\n",
    "                        if key in true_entities:\n",
    "                            true_entities[key]=true_entities[key]+1\n",
    "                        else:\n",
    "                            true_entities[key]=1\n",
    "                    else:\n",
    "                            # Mauvaise prédiction\n",
    "                            if key in wrong_entities:\n",
    "                                wrong_entities[key]=wrong_entities[key]+1\n",
    "                            else:\n",
    "                                wrong_entities[key]=1\n",
    "                else:\n",
    "                    # on trouve pas donc c'est faux\n",
    "                    if key in wrong_entities:\n",
    "                            wrong_entities[key]=wrong_entities[key]+1\n",
    "                    else:\n",
    "                        wrong_entities[key]=1\n",
    "    else:\n",
    "        print(\"pas BookFlight\")\n",
    "        print(input_text)\n",
    "        for col in df_test.columns:\n",
    "            if(col not in ['text','from_start_pos','from_end_pos','to_start_pos','to_end_pos'] and df_test.loc[1,col]!=None):\n",
    "                # on n'a pas trouvé l'intent donc chaque intent de la phrase n'est pas trouvé\n",
    "                if key in wrong_entities:\n",
    "                    wrong_entities[col]=wrong_entities[col]+1\n",
    "                else:\n",
    "                    wrong_entities[col]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'end_date': 31, 'from': 110, 'to': 119, 'str_date': 41, 'budget': 24}\n",
      "{'from': 20, 'end_date': 13, 'to': 22, 'budget': 9, 'str_date': 17}\n"
     ]
    }
   ],
   "source": [
    "print(true_entities)\n",
    "print(wrong_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'end_date': 0.8857142857142857, 'from': 0.7971014492753623, 'to': 0.7986577181208053, 'str_date': 0.6507936507936508, 'budget': 0.7272727272727273}\n"
     ]
    }
   ],
   "source": [
    "entities_acc={}\n",
    "for key, value in true_entities.items():\n",
    "    counterEntityFunc = df_test[key].apply(\n",
    "        lambda x: True if x != None else False)\n",
    "    nb = len(counterEntityFunc[counterEntityFunc == True].index)\n",
    "    entities_acc[key]= int(value)/nb\n",
    "\n",
    "print(entities_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Création d'une application luis complète avec un json\n",
    "\n",
    "# import requests\n",
    "\n",
    "# struct_pyth = luis_json.luis_structure_python()\n",
    "# struct_json = json.dumps(struct_pyth)\n",
    "# json.dump\n",
    "\n",
    "# url = 'https://luisp10-authoring.cognitiveservices.azure.com/luis/authoring/v3.0-preview/apps/import'\n",
    "\n",
    "# headers={\n",
    "#     'content-type': 'application/json',\n",
    "#     'Ocp-apim-subscription-key':'99ce3768cc2c485ea84238e1e9a52e8d'\n",
    "# }\n",
    "# params={\n",
    "#     'Endpoint':'https://luisp10-authoring.cognitiveservices.azure.com/'\n",
    "# }\n",
    "\n",
    "# x = requests.post(url, headers=headers, params=params, data=struct_json)\n",
    "\n",
    "# print(x.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0a366b0796e49b1c4259cbe27201f4b1dcd4c931e08226cc714245a83ad7a53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
